{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from ignite.metrics import EpochMetric\n",
    "from ignite.contrib.metrics import roc_auc, ROC_AUC, RocCurve\n",
    "from torchvision import datasets, transforms\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.metrics import Accuracy, Precision, Recall, ConfusionMatrix, Fbeta, Loss, MetricsLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to help set the final classifier layer and other basic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-process the data to make sure it is properly formatted for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the image data for training and validation sets\n",
    "\n",
    "def preprocess_data(train_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Train',\n",
    "                    test_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Val'):\n",
    "\n",
    "    # transform the train and validation data\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # standard pytorch normalization values\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "    # collect in a dictionary\n",
    "    image_datasets = {}\n",
    "    image_datasets['train'] = datasets.ImageFolder(train_data_dir, data_transforms['train'])\n",
    "    image_datasets['val'] = datasets.ImageFolder(test_data_dir, data_transforms['val'])\n",
    "\n",
    "\n",
    "    # create data loaders\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['val'].classes\n",
    "\n",
    "    return class_names, dataset_sizes, dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function is the global one. It initializes the model, the parameters that need to be trained/tuned, processes the data, and runs the trainier and executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(model_name = 'alexnet', num_classes = 2, num_epochs = 10, device = torch.device(\"cpu\"),\n",
    "                    feature_extract = True, criterion = nn.CrossEntropyLoss()):\n",
    "    # Initialize the model for this run\n",
    "    model = [models.resnet18(pretrained=use_pretrained) if model_name == 'resnet' else models.resnet18(pretrained=use_pretrained)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "    model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "    # Print the model we just instantiated\n",
    "    print(model)\n",
    "\n",
    "    # get data downloaders\n",
    "    class_names, dataset_sizes, dataloaders_dict = preprocess_data()\n",
    "    \n",
    "    # Send the model to GPU/CPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
    "    \n",
    "    train_dl = dataloaders_dict['train']\n",
    "    val_dl = dataloaders_dict['val']\n",
    "    \n",
    "    \n",
    "    # create a trainer and evaluator using the ignite package to train and evaluate the models\n",
    "    trainer = create_supervised_trainer(model, optimizer_ft, criterion, device)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics={'accuracy': Accuracy(),\n",
    "                                                     'confusion': ConfusionMatrix(num_classes = 2),\n",
    "                                                     'loss': Loss(criterion)},\n",
    "                                            device=device)\n",
    "    \n",
    "    # attach additional metrics\n",
    "    precision = Precision(average=False)\n",
    "    recall = Recall(average=False)\n",
    "    F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "    precision.attach(evaluator, 'precision')\n",
    "    recall.attach(evaluator, 'recall')\n",
    "    F1.attach(evaluator, 'F1')\n",
    "    \n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        evaluator.run(train_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "#         pred, y = evaluator.state.output\n",
    "#         ra = ROC_AUC(activated_output_transform(evaluator.state.output), True)\n",
    "#         val = ra.roc_auc_compute_fn([pred, y])\n",
    "        print(\n",
    "            f\"Training Results   - Epoch: {trainer.state.epoch}  \"\n",
    "            f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "            f\"loss: {metrics['loss']:.2f} \"\n",
    "            f\"prec: {metrics['precision'].cpu()} \"\n",
    "            f\"recall: {metrics['recall'].cpu()} \"\n",
    "            f\"F1: {metrics['F1']}\")\n",
    "#             f\"ROC AUC: {roc_auc_val:.2f} \"\n",
    "#             f\"ROC Curve: {roc_auc_curve:.2f}\"\n",
    "#         )\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "#         pred, y = evaluator.state.output\n",
    "        print(\n",
    "            f\"Validation Results - Epoch: {trainer.state.epoch}  \"\n",
    "            f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "            f\"loss: {metrics['loss']:.2f} \"\n",
    "            f\"prec: {metrics['precision'].cpu()} \"\n",
    "            f\"recall: {metrics['recall'].cpu()} \"\n",
    "            f\"F1: {metrics['F1']}\")\n",
    "#             f\"ROC AUC: {roc_auc_val:.2f} \"\n",
    "#             f\"ROC Curve: {roc_auc_curve:.2f}\"\n",
    "#         )\n",
    "\n",
    "\n",
    "    trainer.run(train_dl, max_epochs=15)\n",
    "    return trainer, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n",
      "Training Results   - Epoch: 1  accuracy: 0.64 loss: 0.64 prec: tensor([0.5983, 0.7075], dtype=torch.float64) recall: tensor([0.7335, 0.5670], dtype=torch.float64) F1: 0.6442784698879107\n",
      "Validation Results - Epoch: 1  accuracy: 0.66 loss: 0.67 prec: tensor([0.6642, 0.6440], dtype=torch.float64) recall: tensor([0.7280, 0.5721], dtype=torch.float64) F1: 0.6502839092994397\n",
      "Training Results   - Epoch: 2  accuracy: 0.68 loss: 0.59 prec: tensor([0.7028, 0.6618], dtype=torch.float64) recall: tensor([0.5343, 0.8013], dtype=torch.float64) F1: 0.6659760151140229\n",
      "Validation Results - Epoch: 2  accuracy: 0.63 loss: 0.68 prec: tensor([0.7083, 0.5824], dtype=torch.float64) recall: tensor([0.5440, 0.7395], dtype=torch.float64) F1: 0.6335119798234552\n",
      "Training Results   - Epoch: 3  accuracy: 0.62 loss: 0.70 prec: tensor([0.5579, 0.8072], dtype=torch.float64) recall: tensor([0.8985, 0.3739], dtype=torch.float64) F1: 0.5997206984615053\n",
      "Validation Results - Epoch: 3  accuracy: 0.62 loss: 0.76 prec: tensor([0.5983, 0.6731], dtype=torch.float64) recall: tensor([0.8640, 0.3256], dtype=torch.float64) F1: 0.5729545582810439\n",
      "Training Results   - Epoch: 4  accuracy: 0.68 loss: 0.59 prec: tensor([0.6225, 0.7649], dtype=torch.float64) recall: tensor([0.7995, 0.5737], dtype=torch.float64) F1: 0.6778061224489795\n",
      "Validation Results - Epoch: 4  accuracy: 0.64 loss: 0.72 prec: tensor([0.6309, 0.6622], dtype=torch.float64) recall: tensor([0.8000, 0.4558], dtype=torch.float64) F1: 0.6227061378576529\n",
      "Training Results   - Epoch: 5  accuracy: 0.68 loss: 0.60 prec: tensor([0.7771, 0.6489], dtype=torch.float64) recall: tensor([0.4556, 0.8850], dtype=torch.float64) F1: 0.6616098205854579\n",
      "Validation Results - Epoch: 5  accuracy: 0.58 loss: 0.81 prec: tensor([0.6800, 0.5302], dtype=torch.float64) recall: tensor([0.4080, 0.7767], dtype=torch.float64) F1: 0.5700943396226414\n",
      "Training Results   - Epoch: 6  accuracy: 0.67 loss: 0.63 prec: tensor([0.8367, 0.6264], dtype=torch.float64) recall: tensor([0.3642, 0.9375], dtype=torch.float64) F1: 0.6292606421936034\n",
      "Validation Results - Epoch: 6  accuracy: 0.58 loss: 0.82 prec: tensor([0.7236, 0.5292], dtype=torch.float64) recall: tensor([0.3560, 0.8419], dtype=torch.float64) F1: 0.5635610148199133\n",
      "Training Results   - Epoch: 7  accuracy: 0.62 loss: 0.75 prec: tensor([0.8261, 0.5887], dtype=torch.float64) recall: tensor([0.2411, 0.9554], dtype=torch.float64) F1: 0.5508957906617062\n",
      "Validation Results - Epoch: 7  accuracy: 0.52 loss: 1.01 prec: tensor([0.6883, 0.4923], dtype=torch.float64) recall: tensor([0.2120, 0.8884], dtype=torch.float64) F1: 0.47882909610966584\n",
      "Training Results   - Epoch: 8  accuracy: 0.71 loss: 0.55 prec: tensor([0.6652, 0.7714], dtype=torch.float64) recall: tensor([0.7792, 0.6551], dtype=torch.float64) F1: 0.7131091481968885\n",
      "Validation Results - Epoch: 8  accuracy: 0.59 loss: 0.76 prec: tensor([0.6021, 0.5682], dtype=torch.float64) recall: tensor([0.6960, 0.4651], dtype=torch.float64) F1: 0.5785745128090761\n",
      "Training Results   - Epoch: 9  accuracy: 0.73 loss: 0.53 prec: tensor([0.7237, 0.7335], dtype=torch.float64) recall: tensor([0.6815, 0.7712], dtype=torch.float64) F1: 0.7269325140284623\n",
      "Validation Results - Epoch: 9  accuracy: 0.60 loss: 0.75 prec: tensor([0.6320, 0.5721], dtype=torch.float64) recall: tensor([0.6320, 0.5721], dtype=torch.float64) F1: 0.602046511627907\n",
      "Training Results   - Epoch: 10  accuracy: 0.69 loss: 0.64 prec: tensor([0.7514, 0.6641], dtype=torch.float64) recall: tensor([0.5102, 0.8516], dtype=torch.float64) F1: 0.6769600097577744\n",
      "Validation Results - Epoch: 10  accuracy: 0.57 loss: 0.92 prec: tensor([0.6604, 0.5261], dtype=torch.float64) recall: tensor([0.4200, 0.7488], dtype=torch.float64) F1: 0.5657448296251801\n",
      "Training Results   - Epoch: 11  accuracy: 0.72 loss: 0.54 prec: tensor([0.7927, 0.6874], dtype=torch.float64) recall: tensor([0.5482, 0.8739], dtype=torch.float64) F1: 0.7088476050216486\n",
      "Validation Results - Epoch: 11  accuracy: 0.57 loss: 0.82 prec: tensor([0.6538, 0.5210], dtype=torch.float64) recall: tensor([0.4080, 0.7488], dtype=torch.float64) F1: 0.5584834354905426\n",
      "Training Results   - Epoch: 12  accuracy: 0.73 loss: 0.56 prec: tensor([0.7566, 0.7113], dtype=torch.float64) recall: tensor([0.6193, 0.8248], dtype=torch.float64) F1: 0.7224564573336867\n",
      "Validation Results - Epoch: 12  accuracy: 0.60 loss: 0.83 prec: tensor([0.6524, 0.5569], dtype=torch.float64) recall: tensor([0.5480, 0.6605], dtype=torch.float64) F1: 0.5999537465309899\n",
      "Training Results   - Epoch: 13  accuracy: 0.61 loss: 0.77 prec: tensor([0.5493, 0.8987], dtype=torch.float64) recall: tensor([0.9607, 0.3069], dtype=torch.float64) F1: 0.5782775091683144\n",
      "Validation Results - Epoch: 13  accuracy: 0.60 loss: 0.93 prec: tensor([0.5795, 0.6800], dtype=torch.float64) recall: tensor([0.9040, 0.2372], dtype=torch.float64) F1: 0.5289870689655173\n",
      "Training Results   - Epoch: 14  accuracy: 0.71 loss: 0.56 prec: tensor([0.7066, 0.7205], dtype=torch.float64) recall: tensor([0.6662, 0.7567], dtype=torch.float64) F1: 0.7119931504487018\n",
      "Validation Results - Epoch: 14  accuracy: 0.60 loss: 0.89 prec: tensor([0.6255, 0.5654], dtype=torch.float64) recall: tensor([0.6280, 0.5628], dtype=torch.float64) F1: 0.595424535544296\n",
      "Training Results   - Epoch: 15  accuracy: 0.72 loss: 0.55 prec: tensor([0.8431, 0.6727], dtype=torch.float64) recall: tensor([0.4911, 0.9196], dtype=torch.float64) F1: 0.6988408200425953\n",
      "Validation Results - Epoch: 15  accuracy: 0.57 loss: 0.84 prec: tensor([0.6543, 0.5248], dtype=torch.float64) recall: tensor([0.4240, 0.7395], dtype=torch.float64) F1: 0.5642313603478653\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results   - Epoch: 1  accuracy: 0.55 loss: 0.86 prec: tensor([0.9024, 0.5429], dtype=torch.float64) recall: tensor([0.0470, 0.9955], dtype=torch.float64) F1: 0.3959515039449723\n",
      "Validation Results - Epoch: 1  accuracy: 0.49 loss: 0.99 prec: tensor([0.9231, 0.4735], dtype=torch.float64) recall: tensor([0.0480, 0.9953], dtype=torch.float64) F1: 0.3664669566357506\n",
      "Training Results   - Epoch: 2  accuracy: 0.67 loss: 0.61 prec: tensor([0.7568, 0.6342], dtype=torch.float64) recall: tensor([0.4226, 0.8806], dtype=torch.float64) F1: 0.6398642272215289\n",
      "Validation Results - Epoch: 2  accuracy: 0.59 loss: 0.69 prec: tensor([0.6928, 0.5385], dtype=torch.float64) recall: tensor([0.4240, 0.7814], dtype=torch.float64) F1: 0.5818128740329879\n",
      "Training Results   - Epoch: 3  accuracy: 0.69 loss: 0.58 prec: tensor([0.7390, 0.6697], dtype=torch.float64) recall: tensor([0.5317, 0.8348], dtype=torch.float64) F1: 0.6808097917044744\n",
      "Validation Results - Epoch: 3  accuracy: 0.62 loss: 0.66 prec: tensor([0.7049, 0.5709], dtype=torch.float64) recall: tensor([0.5160, 0.7488], dtype=torch.float64) F1: 0.6218651400318771\n",
      "Training Results   - Epoch: 4  accuracy: 0.65 loss: 0.60 prec: tensor([0.5903, 0.7851], dtype=torch.float64) recall: tensor([0.8503, 0.4810], dtype=torch.float64) F1: 0.6466838327512339\n",
      "Validation Results - Epoch: 4  accuracy: 0.63 loss: 0.65 prec: tensor([0.6138, 0.6565], dtype=torch.float64) recall: tensor([0.8200, 0.4000], dtype=torch.float64) F1: 0.5995823105550717\n",
      "Training Results   - Epoch: 5  accuracy: 0.69 loss: 0.58 prec: tensor([0.6271, 0.7759], dtype=torch.float64) recall: tensor([0.8109, 0.5759], dtype=torch.float64) F1: 0.6841821275153532\n",
      "Validation Results - Epoch: 5  accuracy: 0.60 loss: 0.67 prec: tensor([0.6026, 0.5948], dtype=torch.float64) recall: tensor([0.7520, 0.4233], dtype=torch.float64) F1: 0.5818021816493889\n",
      "Training Results   - Epoch: 6  accuracy: 0.71 loss: 0.55 prec: tensor([0.7033, 0.7234], dtype=torch.float64) recall: tensor([0.6739, 0.7500], dtype=torch.float64) F1: 0.7123539804153092\n",
      "Validation Results - Epoch: 6  accuracy: 0.65 loss: 0.64 prec: tensor([0.6822, 0.6114], dtype=torch.float64) recall: tensor([0.6440, 0.6512], dtype=torch.float64) F1: 0.6465910354799245\n",
      "Training Results   - Epoch: 7  accuracy: 0.60 loss: 0.76 prec: tensor([0.9296, 0.5746], dtype=torch.float64) recall: tensor([0.1675, 0.9888], dtype=torch.float64) F1: 0.5053481171769562\n",
      "Validation Results - Epoch: 7  accuracy: 0.50 loss: 0.93 prec: tensor([0.7576, 0.4792], dtype=torch.float64) recall: tensor([0.1000, 0.9628], dtype=torch.float64) F1: 0.40827739881267716\n",
      "Training Results   - Epoch: 8  accuracy: 0.67 loss: 0.61 prec: tensor([0.8412, 0.6265], dtype=torch.float64) recall: tensor([0.3629, 0.9397], dtype=torch.float64) F1: 0.6294389564336373\n",
      "Validation Results - Epoch: 8  accuracy: 0.57 loss: 0.75 prec: tensor([0.7182, 0.5183], dtype=torch.float64) recall: tensor([0.3160, 0.8558], dtype=torch.float64) F1: 0.5422514619883041\n",
      "Training Results   - Epoch: 9  accuracy: 0.53 loss: 0.94 prec: tensor([0.4997, 0.8905], dtype=torch.float64) recall: tensor([0.9810, 0.1362], dtype=torch.float64) F1: 0.44915186428170173\n",
      "Validation Results - Epoch: 9  accuracy: 0.58 loss: 0.98 prec: tensor([0.5598, 0.9091], dtype=torch.float64) recall: tensor([0.9920, 0.0930], dtype=torch.float64) F1: 0.4422525435183663\n",
      "Training Results   - Epoch: 10  accuracy: 0.71 loss: 0.54 prec: tensor([0.6835, 0.7421], dtype=torch.float64) recall: tensor([0.7208, 0.7065], dtype=torch.float64) F1: 0.712754945824509\n",
      "Validation Results - Epoch: 10  accuracy: 0.62 loss: 0.65 prec: tensor([0.6506, 0.5926], dtype=torch.float64) recall: tensor([0.6480, 0.5953], dtype=torch.float64) F1: 0.6216330572978904\n",
      "Training Results   - Epoch: 11  accuracy: 0.72 loss: 0.54 prec: tensor([0.7597, 0.7004], dtype=torch.float64) recall: tensor([0.5939, 0.8348], dtype=torch.float64) F1: 0.7141887304820096\n",
      "Validation Results - Epoch: 11  accuracy: 0.61 loss: 0.68 prec: tensor([0.6735, 0.5613], dtype=torch.float64) recall: tensor([0.5280, 0.7023], dtype=torch.float64) F1: 0.6079475966349182\n",
      "Training Results   - Epoch: 12  accuracy: 0.73 loss: 0.54 prec: tensor([0.7515, 0.7148], dtype=torch.float64) recall: tensor([0.6294, 0.8170], dtype=torch.float64) F1: 0.7237914364640884\n",
      "Validation Results - Epoch: 12  accuracy: 0.61 loss: 0.67 prec: tensor([0.6575, 0.5691], dtype=torch.float64) recall: tensor([0.5760, 0.6512], dtype=torch.float64) F1: 0.6107238829095921\n",
      "Training Results   - Epoch: 13  accuracy: 0.67 loss: 0.61 prec: tensor([0.8529, 0.6295], dtype=torch.float64) recall: tensor([0.3680, 0.9442], dtype=torch.float64) F1: 0.6347707700101317\n",
      "Validation Results - Epoch: 13  accuracy: 0.58 loss: 0.77 prec: tensor([0.7857, 0.5286], dtype=torch.float64) recall: tensor([0.3080, 0.9023], dtype=torch.float64) F1: 0.5545977011494253\n",
      "Training Results   - Epoch: 14  accuracy: 0.73 loss: 0.53 prec: tensor([0.6926, 0.7750], dtype=torch.float64) recall: tensor([0.7690, 0.6998], dtype=torch.float64) F1: 0.7321436191880201\n",
      "Validation Results - Epoch: 14  accuracy: 0.62 loss: 0.65 prec: tensor([0.6370, 0.6000], dtype=torch.float64) recall: tensor([0.6880, 0.5442], dtype=torch.float64) F1: 0.6161350844277673\n",
      "Training Results   - Epoch: 15  accuracy: 0.71 loss: 0.55 prec: tensor([0.6531, 0.7937], dtype=torch.float64) recall: tensor([0.8173, 0.6183], dtype=torch.float64) F1: 0.7105747454872344\n",
      "Validation Results - Epoch: 15  accuracy: 0.63 loss: 0.67 prec: tensor([0.6339, 0.6294], dtype=torch.float64) recall: tensor([0.7480, 0.4977], dtype=torch.float64) F1: 0.6210413439771238\n"
     ]
    }
   ],
   "source": [
    "# run the analysis on alexnet and resnet\n",
    "models_final = {}\n",
    "for model in ['alexnet', 'resnet']:\n",
    "    trainer, evaluator = build_and_train(model)\n",
    "    models_final[model] = (trainer, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
