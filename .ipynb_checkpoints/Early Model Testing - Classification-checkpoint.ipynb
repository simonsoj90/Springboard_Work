{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from ignite.metrics import EpochMetric\n",
    "from torchvision import datasets, transforms\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.metrics import Accuracy, Precision, Recall, ConfusionMatrix, Fbeta, Loss, MetricsLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, device = torch.device(\"cpu\"), num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch +1 , num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Train',\n",
    "                    test_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Val'):\n",
    "\n",
    "    # transform the train and validation data\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # standard pytorch normalization values\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "    # collect in a dictionary\n",
    "\n",
    "\n",
    "    image_datasets = {}\n",
    "    image_datasets['train'] = datasets.ImageFolder(train_data_dir, data_transforms['train'])\n",
    "    image_datasets['val'] = datasets.ImageFolder(test_data_dir, data_transforms['val'])\n",
    "\n",
    "\n",
    "    # create data loaders\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['val'].classes\n",
    "\n",
    "    # training on local machine\n",
    "    return class_names, dataset_sizes, dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(model_name = 'alexnet', num_classes = 2, num_epochs = 10, device = torch.device(\"cpu\"),\n",
    "                    feature_extract = True, criterion = nn.CrossEntropyLoss()):\n",
    "    # Initialize the model for this run\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "    # Print the model we just instantiated\n",
    "    print(model_ft)\n",
    "\n",
    "    # get data downloaders\n",
    "    class_names, dataset_sizes, dataloaders_dict = preprocess_data()\n",
    "    \n",
    "    # Send the model to GPU/CPU\n",
    "    model_ft = model_ft.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run. If we are\n",
    "    #  finetuning we will be updating all parameters. However, if we are\n",
    "    #  doing feature extract method, we will only update the parameters\n",
    "    #  that we have just initialized, i.e. the parameters with requires_grad\n",
    "    #  is True.\n",
    "    params_to_update = model_ft.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=0.001)#, momentum=0.9)\n",
    "    \n",
    "    train_dl = dataloaders_dict['train']\n",
    "    val_dl = dataloaders_dict['val']\n",
    "    \n",
    "    trainer = create_supervised_trainer(model_ft, optimizer_ft, criterion, device)\n",
    "    evaluator = create_supervised_evaluator(model_ft,\n",
    "                                            metrics={'accuracy': Accuracy(), 'precision': Precision(),\n",
    "                                                     'confusion': ConfusionMatrix(num_classes = 2),\n",
    "                                                     'loss': Loss(criterion), 'recall': Recall()},\n",
    "                                            device=device)\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        evaluator.run(train_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "        p, r = metrics['precision'], metrics['recall']\n",
    "        F1 = p * r * 2 / (p + r + 1e-20)\n",
    "        F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n",
    "        print(\n",
    "            f\"Training Results   - Epoch: {trainer.state.epoch}  \"\n",
    "            f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "            f\"loss: {metrics['loss']:.2f} \"\n",
    "            f\"prec: {metrics['precision'].cpu()} \"\n",
    "            f\"confusion: {metrics['confusion']} \"\n",
    "            f\"F1: {F1}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "        p, r = metrics['precision'], metrics['recall']\n",
    "        F1 = p * r * 2 / (p + r + 1e-20)\n",
    "        F1 = MetricsLambda(lambda t: torch.mean(t).item(), F1)\n",
    "        print(\n",
    "            f\"Validation Results - Epoch: {trainer.state.epoch}  \"\n",
    "            f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "            f\"loss: {metrics['loss']:.2f} \"\n",
    "            f\"prec: {metrics['precision'].cpu()} \"\n",
    "            f\"confusion: {metrics['confusion']} \"\n",
    "            f\"F1: {F1}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.run(train_dl, max_epochs=15)\n",
    "    return trainer, evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n",
      "Training Results   - Epoch: 1  accuracy: 0.63 loss: 0.65 prec: tensor([0.5737, 0.7141], dtype=torch.float64) confusion: tensor([[611, 177],\n",
      "        [454, 442]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf50231190>\n",
      "Validation Results - Epoch: 1  accuracy: 0.63 loss: 0.66 prec: tensor([0.6439, 0.6203], dtype=torch.float64) confusion: tensor([[179,  71],\n",
      "        [ 99, 116]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf011822d0>\n",
      "Training Results   - Epoch: 2  accuracy: 0.61 loss: 0.76 prec: tensor([0.7948, 0.5835], dtype=torch.float64) confusion: tensor([[182, 606],\n",
      "        [ 47, 849]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf41064610>\n",
      "Validation Results - Epoch: 2  accuracy: 0.50 loss: 0.97 prec: tensor([0.5952, 0.4751], dtype=torch.float64) confusion: tensor([[ 50, 200],\n",
      "        [ 34, 181]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf41064610>\n",
      "Training Results   - Epoch: 3  accuracy: 0.66 loss: 0.62 prec: tensor([0.6439, 0.6724], dtype=torch.float64) confusion: tensor([[481, 307],\n",
      "        [266, 630]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf011822d0>\n",
      "Validation Results - Epoch: 3  accuracy: 0.58 loss: 0.80 prec: tensor([0.6186, 0.5459], dtype=torch.float64) confusion: tensor([[146, 104],\n",
      "        [ 90, 125]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf011822d0>\n",
      "Training Results   - Epoch: 4  accuracy: 0.69 loss: 0.56 prec: tensor([0.6364, 0.7598], dtype=torch.float64) confusion: tensor([[616, 172],\n",
      "        [352, 544]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf50231190>\n",
      "Validation Results - Epoch: 4  accuracy: 0.66 loss: 0.70 prec: tensor([0.6632, 0.6667], dtype=torch.float64) confusion: tensor([[191,  59],\n",
      "        [ 97, 118]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf50231190>\n",
      "Training Results   - Epoch: 5  accuracy: 0.66 loss: 0.63 prec: tensor([0.5882, 0.8176], dtype=torch.float64) confusion: tensor([[697,  91],\n",
      "        [488, 408]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf314098d0>\n",
      "Validation Results - Epoch: 5  accuracy: 0.63 loss: 0.82 prec: tensor([0.6117, 0.7103], dtype=torch.float64) confusion: tensor([[219,  31],\n",
      "        [139,  76]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf312cb810>\n",
      "Training Results   - Epoch: 6  accuracy: 0.66 loss: 0.68 prec: tensor([0.7842, 0.6199], dtype=torch.float64) confusion: tensor([[287, 501],\n",
      "        [ 79, 817]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf6053fdd0>\n",
      "Validation Results - Epoch: 6  accuracy: 0.58 loss: 0.90 prec: tensor([0.7436, 0.5316], dtype=torch.float64) confusion: tensor([[ 87, 163],\n",
      "        [ 30, 185]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf6053fdd0>\n",
      "Training Results   - Epoch: 7  accuracy: 0.69 loss: 0.58 prec: tensor([0.6163, 0.8354], dtype=torch.float64) confusion: tensor([[697,  91],\n",
      "        [434, 462]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf501d0310>\n",
      "Validation Results - Epoch: 7  accuracy: 0.64 loss: 0.74 prec: tensor([0.6188, 0.6855], dtype=torch.float64) confusion: tensor([[211,  39],\n",
      "        [130,  85]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf312cb810>\n",
      "Training Results   - Epoch: 8  accuracy: 0.59 loss: 0.90 prec: tensor([0.9815, 0.5673], dtype=torch.float64) confusion: tensor([[106, 682],\n",
      "        [  2, 894]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf41092dd0>\n",
      "Validation Results - Epoch: 8  accuracy: 0.50 loss: 1.19 prec: tensor([0.7576, 0.4792], dtype=torch.float64) confusion: tensor([[ 25, 225],\n",
      "        [  8, 207]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf41092dd0>\n",
      "Training Results   - Epoch: 9  accuracy: 0.68 loss: 0.63 prec: tensor([0.6098, 0.8278], dtype=torch.float64) confusion: tensor([[694,  94],\n",
      "        [444, 452]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313adc10>\n",
      "Validation Results - Epoch: 9  accuracy: 0.57 loss: 0.87 prec: tensor([0.5774, 0.5659], dtype=torch.float64) confusion: tensor([[194,  56],\n",
      "        [142,  73]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313adc10>\n",
      "Training Results   - Epoch: 10  accuracy: 0.70 loss: 0.55 prec: tensor([0.6281, 0.8468], dtype=torch.float64) confusion: tensor([[701,  87],\n",
      "        [415, 481]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf41092510>\n",
      "Validation Results - Epoch: 10  accuracy: 0.62 loss: 0.78 prec: tensor([0.6023, 0.6525], dtype=torch.float64) confusion: tensor([[209,  41],\n",
      "        [138,  77]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313d0b50>\n",
      "Training Results   - Epoch: 11  accuracy: 0.65 loss: 0.77 prec: tensor([0.8783, 0.6080], dtype=torch.float64) confusion: tensor([[231, 557],\n",
      "        [ 32, 864]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf60560f90>\n",
      "Validation Results - Epoch: 11  accuracy: 0.52 loss: 1.04 prec: tensor([0.6452, 0.4892], dtype=torch.float64) confusion: tensor([[ 60, 190],\n",
      "        [ 33, 182]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf60560f90>\n",
      "Training Results   - Epoch: 12  accuracy: 0.61 loss: 0.80 prec: tensor([0.5466, 0.8963], dtype=torch.float64) confusion: tensor([[757,  31],\n",
      "        [628, 268]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313dd6d0>\n",
      "Validation Results - Epoch: 12  accuracy: 0.61 loss: 0.95 prec: tensor([0.5875, 0.7692], dtype=torch.float64) confusion: tensor([[235,  15],\n",
      "        [165,  50]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf3104e390>\n",
      "Training Results   - Epoch: 13  accuracy: 0.73 loss: 0.53 prec: tensor([0.7304, 0.7262], dtype=torch.float64) confusion: tensor([[523, 265],\n",
      "        [193, 703]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf300dcb50>\n",
      "Validation Results - Epoch: 13  accuracy: 0.57 loss: 0.81 prec: tensor([0.6133, 0.5333], dtype=torch.float64) confusion: tensor([[138, 112],\n",
      "        [ 87, 128]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf300dcb50>\n",
      "Training Results   - Epoch: 14  accuracy: 0.70 loss: 0.55 prec: tensor([0.6615, 0.7516], dtype=torch.float64) confusion: tensor([[592, 196],\n",
      "        [303, 593]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf31039750>\n",
      "Validation Results - Epoch: 14  accuracy: 0.59 loss: 0.81 prec: tensor([0.6034, 0.5765], dtype=torch.float64) confusion: tensor([[178,  72],\n",
      "        [117,  98]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf31039750>\n",
      "Training Results   - Epoch: 15  accuracy: 0.71 loss: 0.55 prec: tensor([0.7367, 0.6960], dtype=torch.float64) confusion: tensor([[470, 318],\n",
      "        [168, 728]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf4108ca90>\n",
      "Validation Results - Epoch: 15  accuracy: 0.62 loss: 0.79 prec: tensor([0.6919, 0.5643], dtype=torch.float64) confusion: tensor([[128, 122],\n",
      "        [ 57, 158]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf4108ca90>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Training Results   - Epoch: 1  accuracy: 0.60 loss: 0.71 prec: tensor([0.8537, 0.5737], dtype=torch.float64) confusion: tensor([[140, 648],\n",
      "        [ 24, 872]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf510bee10>\n",
      "Validation Results - Epoch: 1  accuracy: 0.52 loss: 0.80 prec: tensor([0.8537, 0.4929], dtype=torch.float64) confusion: tensor([[ 35, 215],\n",
      "        [  6, 209]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf510bee10>\n",
      "Training Results   - Epoch: 2  accuracy: 0.62 loss: 0.68 prec: tensor([0.8136, 0.5884], dtype=torch.float64) confusion: tensor([[192, 596],\n",
      "        [ 44, 852]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf510bca10>\n",
      "Validation Results - Epoch: 2  accuracy: 0.55 loss: 0.77 prec: tensor([0.8448, 0.5061], dtype=torch.float64) confusion: tensor([[ 49, 201],\n",
      "        [  9, 206]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf300dcb50>\n",
      "Training Results   - Epoch: 3  accuracy: 0.64 loss: 0.64 prec: tensor([0.8081, 0.6049], dtype=torch.float64) confusion: tensor([[240, 548],\n",
      "        [ 57, 839]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faec0332d90>\n",
      "Validation Results - Epoch: 3  accuracy: 0.57 loss: 0.74 prec: tensor([0.7976, 0.5197], dtype=torch.float64) confusion: tensor([[ 67, 183],\n",
      "        [ 17, 198]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf31409450>\n",
      "Training Results   - Epoch: 4  accuracy: 0.70 loss: 0.57 prec: tensor([0.6583, 0.7395], dtype=torch.float64) confusion: tensor([[578, 210],\n",
      "        [300, 596]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313f7bd0>\n",
      "Validation Results - Epoch: 4  accuracy: 0.63 loss: 0.64 prec: tensor([0.6400, 0.6105], dtype=torch.float64) confusion: tensor([[176,  74],\n",
      "        [ 99, 116]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf31409350>\n",
      "Training Results   - Epoch: 5  accuracy: 0.67 loss: 0.60 prec: tensor([0.6078, 0.7949], dtype=torch.float64) confusion: tensor([[668, 120],\n",
      "        [431, 465]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313dd210>\n",
      "Validation Results - Epoch: 5  accuracy: 0.63 loss: 0.66 prec: tensor([0.6138, 0.6565], dtype=torch.float64) confusion: tensor([[205,  45],\n",
      "        [129,  86]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313d7d90>\n",
      "Training Results   - Epoch: 6  accuracy: 0.70 loss: 0.55 prec: tensor([0.6774, 0.7244], dtype=torch.float64) confusion: tensor([[546, 242],\n",
      "        [260, 636]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313f71d0>\n",
      "Validation Results - Epoch: 6  accuracy: 0.63 loss: 0.66 prec: tensor([0.6586, 0.6019], dtype=torch.float64) confusion: tensor([[164,  86],\n",
      "        [ 85, 130]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313f71d0>\n",
      "Training Results   - Epoch: 7  accuracy: 0.60 loss: 0.78 prec: tensor([0.9431, 0.5695], dtype=torch.float64) confusion: tensor([[116, 672],\n",
      "        [  7, 889]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf31409ad0>\n",
      "Validation Results - Epoch: 7  accuracy: 0.51 loss: 0.96 prec: tensor([0.8333, 0.4828], dtype=torch.float64) confusion: tensor([[ 25, 225],\n",
      "        [  5, 210]]) F1: <ignite.metrics.metrics_lambda.MetricsLambda object at 0x7faf313daad0>\n"
     ]
    }
   ],
   "source": [
    "# alex_model, alex_hist, optimizer, criterion = build_and_train()\n",
    "models_final = {}\n",
    "for model in ['alexnet', 'resnet']:\n",
    "    trainer, evaluator = build_and_train(model)\n",
    "    models_final[model] = (trainer, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_model, resnet_hist = build_and_train('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
