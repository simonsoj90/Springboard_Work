{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an overview of the 3 datasets I explored in researching data for my capstone project. I explored a handful of other datasets, but I intend to use sets 1 and 2 below. I chose the COCO dataset over the Pascal VOC for training a model due to the larger size and more common-usage (easier to use since there is a lot of demonstration online). All datasets are too large to upload to GitHub using the LFS. Instead, they are stored on a personal external hard-drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common Objects in Context (COCO)\n",
    "\n",
    "The COCO 2017 dataset is a common object-detection dataset used as a benchmark for model training and evaluation. It contains sets of training, testing, and validation images and annotations (the testing images lack annotations). The data is extracted via [TensorFlow](https://www.tensorflow.org/datasets/catalog/coco).\n",
    "\n",
    "Data collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "path = \"D:/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
      "252878848/252872794 [==============================] - 52s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# download image annotations\n",
    "annotation_folder = '/annotations/'\n",
    "annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
    "                                      cache_subdir=path,\n",
    "                                      origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
    "                                      extract = True)\n",
    "annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
    "os.remove(annotation_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/train2014.zip\n",
      "13510574080/13510573713 [==============================] - 2067s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# download train set\n",
    "image_folder = '/train2014/'\n",
    "image_zip = tf.keras.utils.get_file('train2014.zip',\n",
    "                                  cache_subdir=path,\n",
    "                                  origin = 'http://images.cocodataset.org/zips/train2014.zip',\n",
    "                                  extract = True)\n",
    "PATH = os.path.dirname(image_zip) + image_folder\n",
    "os.remove(image_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/val2014.zip\n",
      "6645014528/6645013297 [==============================] - 857s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# download validation set\n",
    "image_folder= '/val2014/'\n",
    "image_zip = tf.keras.utils.get_file('val2014.zip',\n",
    "                                  cache_subdir=path,\n",
    "                                  origin = 'http://images.cocodataset.org/zips/val2014.zip',\n",
    "                                  extract = True)\n",
    "PATH = os.path.dirname(image_zip) + image_folder\n",
    "os.remove(image_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://images.cocodataset.org/zips/test2014.zip\n",
      "6660440064/6660437059 [==============================] - 2617s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# download test set\n",
    "path = \"D:/\"\n",
    "image_folder= '/test2014/'\n",
    "image_zip = tf.keras.utils.get_file('test2014.zip',\n",
    "                                  cache_subdir=path,\n",
    "                                  origin = 'http://images.cocodataset.org/zips/test2014.zip',\n",
    "                                  extract = True)\n",
    "PATH = os.path.dirname(image_zip) + image_folder\n",
    "os.remove(image_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Breast Cancer Images\n",
    "The CBIS-DDSM ([Curated Breast Imaging Subset of DDSM](https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM)) is an updated and standardized version of the Digital Database for Screening Mammography (DDSM). The DDSM is a database of 2,620 scanned film mammography studies. It contains normal, benign, and malignant cases with verified pathology information.\n",
    "\n",
    "The default config is made of patches extracted from the original mammograms, following the description from http://arxiv.org/abs/1708.09427, in order to frame the task to solve in a traditional image classification setting.\n",
    "\n",
    "The data was downloaded manually and converted into PNG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pascal Visual Object Classes\n",
    "This dataset was found via fast.ai. Accessing the dataset was done by simple navigating to the webpage and downloading the .tgz file containing the images. It is a standardised image data sets for object class recognition. It has 20 classes. The train/val data has 11,530 images containing 27,450 ROI annotated objects and 6,929 segmentations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
