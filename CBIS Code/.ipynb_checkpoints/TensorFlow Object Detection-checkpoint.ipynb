{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.models as models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.estimator as estimator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet, inception_v3\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "np.random.seed(123)\n",
    "img_dim = (250, 250)\n",
    "data_dir = '/Users/jacksimonson/data/'\n",
    "model_zoo = '/Users/jacksimonson/models/research/object_detection/g3doc/tf2_detection_zoo.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write label-map pbtxt file\n",
    "label_map = {1: 'benign', 1: 'malignant'}\n",
    "\n",
    "def write_label_map(data_dir, mapping):\n",
    "    with open(\"{}label_map.txt\".format(data_dir), 'a') as the_file:\n",
    "        for i, lab in mapping.items():\n",
    "            the_file.write('item\\n')\n",
    "            the_file.write('{\\n')\n",
    "            the_file.write('name :{}'.format(lab))\n",
    "            the_file.write('\\n')\n",
    "            the_file.write(\"id :'{0}'\".format(i))\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('}\\n')\n",
    "    print('Saved to {}label_map.txt'.format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /Users/jacksimonson/data/label_map.txt\n"
     ]
    }
   ],
   "source": [
    "write_label_map(data_dir, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(mask_path, img_dim):\n",
    "\n",
    "    \"\"\"Compute bounding boxes from masks.\n",
    "\n",
    "    mask: [height, width, num_instances]. Mask pixels are either 1 or 0.\n",
    "\n",
    " \n",
    "\n",
    "    Returns: bbox array [num_instances, (y1, x1, y2, x2)].\n",
    "\n",
    "    \"\"\"\n",
    "    mask = img_to_array(load_img(mask_path, target_size = img_dim))\n",
    "    mask[mask != 0] = 1\n",
    "\n",
    "    m = mask[:, :, 0]\n",
    "\n",
    "    # Bounding box.\n",
    "\n",
    "    horizontal_indicies = np.where(np.any(m, axis=0))[0]\n",
    "\n",
    "    vertical_indicies = np.where(np.any(m, axis=1))[0]\n",
    "\n",
    "    if horizontal_indicies.shape[0]:\n",
    "\n",
    "        x1, x2 = horizontal_indicies[[0, -1]]\n",
    "\n",
    "        y1, y2 = vertical_indicies[[0, -1]]\n",
    "\n",
    "        # x2 and y2 should not be part of the box. Increment by 1.\n",
    "\n",
    "        x2 += 1\n",
    "\n",
    "        y2 += 1\n",
    "\n",
    "    else:\n",
    "\n",
    "        # No mask for this instance. Might happen due to\n",
    "\n",
    "        # resizing or cropping. Set bbox to zeros\n",
    "\n",
    "        x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image_path = 'training-image'\n",
    "# test_image_path = 'test-image'\n",
    "# train_mask_path = 'training-mask'\n",
    "# test_mask_path = 'test-mask'\n",
    "\n",
    "# train_images = os.listdir(os.path.join(data_dir,train_image_path))\n",
    "# test_images = os.listdir(os.path.join(data_dir,test_image_path))\n",
    "# mask_train = os.listdir(os.path.join(data_dir,train_mask_path))\n",
    "# mask_test = os.listdir(os.path.join(data_dir,test_mask_path))\n",
    "\n",
    "\n",
    "# # find intersection of mammograms and masks\n",
    "# train_files = sorted(list(set(train_images).intersection(set(mask_train))))\n",
    "# test_files = sorted(list(set(test_images).intersection(set(mask_test))))\n",
    "\n",
    "# train_file_names = [x for x in train_files if x.endswith('.png')]\n",
    "# test_file_names = [x for x in test_files if x.endswith('.png')]\n",
    "\n",
    "# train_files = [os.path.join(os.path.join(data_dir, train_image_path), img) for img in train_file_names]\n",
    "# train_images = []\n",
    "# for img in train_files:\n",
    "#     if not img.endswith('.png'):\n",
    "#         continue\n",
    "#     im = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "#     x = cv2.resize(im, img_dim)\n",
    "#     train_images += [x]\n",
    "# train_images = np.array(train_images)\n",
    "\n",
    "    \n",
    "# test_files = [os.path.join(os.path.join(data_dir, test_image_path), img) for img in test_file_names]\n",
    "# test_images = []\n",
    "# for img in test_files:\n",
    "#     if not img.endswith('.png'):\n",
    "#         continue\n",
    "#     im = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "#     x = cv2.resize(im, img_dim)\n",
    "#     test_images += [x]\n",
    "# test_images = np.array(test_images)\n",
    "\n",
    "# # encode labels\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# train_labels = [fn.split('/')[-1].split('_')[-1].replace('.png','').lower().strip() for fn in train_files]\n",
    "# le.fit(train_labels)\n",
    "# train_labels = le.transform(train_labels)\n",
    "\n",
    "# test_labels = [fn.split('/')[-1].split('_')[-1].replace('.png','').lower().strip() for fn in test_files]\n",
    "# test_labels = le.transform(test_labels)\n",
    "\n",
    "# # get bounding boxes\n",
    "# mask_train_images = [os.path.join(os.path.join(data_dir, train_mask_path), img_name) for img_name in train_file_names]\n",
    "# mask_test_images = [os.path.join(os.path.join(data_dir, test_mask_path), img_name) for img_name in test_file_names]\n",
    "\n",
    "# # get bounding boxes\n",
    "# train_bound_boxes = np.array([extract_bboxes(img, img_dim) for img in mask_train_images if not img.endswith('.DS_Store')])\n",
    "# test_bound_boxes = np.array([extract_bboxes(img, img_dim) for img in mask_train_images if not img.endswith('.DS_Store')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jacksimonson/data/training-image/Calc-Training_P_00005_RIGHT_CC_MALIGNANT.png',\n",
       " '/Users/jacksimonson/data/training-image/Calc-Training_P_00005_RIGHT_MLO_MALIGNANT.png',\n",
       " '/Users/jacksimonson/data/training-image/Calc-Training_P_00007_LEFT_CC_BENIGN.png',\n",
       " '/Users/jacksimonson/data/training-image/Calc-Training_P_00007_LEFT_MLO_BENIGN.png',\n",
       " '/Users/jacksimonson/data/training-image/Calc-Training_P_00011_LEFT_CC_BENIGN.png']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/Users/jacksimonson/data/training-labels.npy', train_labels)\n",
    "# np.save('/Users/jacksimonson/data/test-labels.npy', test_labels)\n",
    "# np.save('/Users/jacksimonson/data/test-images-array.npy', test_images)\n",
    "# np.save('/Users/jacksimonson/data/training-images-array.npy', train_images)\n",
    "# np.save('/Users/jacksimonson/data/training_bound_boxes.npy', train_bound_boxes)\n",
    "# np.save('/Users/jacksimonson/data/test_bound_boxes.npy', test_bound_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = np.load('/Users/jacksimonson/data/training-labels.npy')\n",
    "# test_labels = np.load('/Users/jacksimonson/data/test-labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {'benign':1, 'malignant':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = np.load('/Users/jacksimonson/data/training-images-array.npy')\n",
    "# test_images = np.load('/Users/jacksimonson/data/test-images-array.npy')\n",
    "# train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def read_examples_list(path):\n",
    "    \"\"\"Read list of training or validation examples.\n",
    "\n",
    "    The file is assumed to contain a single example per line where the first\n",
    "    token in the line is an identifier that allows us to find the image and\n",
    "    annotation xml for that example.\n",
    "\n",
    "    For example, the line:\n",
    "    xyz 3\n",
    "    would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n",
    "\n",
    "    Args:\n",
    "    path: absolute path to examples list file.\n",
    "\n",
    "    Returns:\n",
    "    list of example identifiers (strings).\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(path) as fid:\n",
    "        lines = fid.readlines()\n",
    "    return [line.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "\n",
    "def recursive_parse_xml_to_dict(xml):\n",
    "    \"\"\"Recursively parses XML contents to python dict.\n",
    "\n",
    "    We assume that `object` tags are the only ones that can appear\n",
    "    multiple times at the same level of a tree.\n",
    "\n",
    "    Args:\n",
    "    xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "\n",
    "    Returns:\n",
    "    Python dictionary holding XML contents.\n",
    "    \"\"\"\n",
    "    if not xml:\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = recursive_parse_xml_to_dict(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "        result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'benign', 1:'malignant'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_tf_example(img_data):\n",
    "    \"\"\"Creates a tf.Example proto from sample cat image.\n",
    "\n",
    "    Args:\n",
    "    encoded_cat_image_data: The jpg encoded data of the cat image.\n",
    "\n",
    "    Returns:\n",
    "    example: The created tf.Example.\n",
    "    \"\"\"\n",
    "    im = tf.convert_to_tensor(img_data[1])\n",
    "    lab = img_data[3]\n",
    "    x1,y1,x2,y2 = img_data[2]\n",
    "    filename = img_data[0].encode('utf-8')\n",
    "\n",
    "    img = tf.image.decode_png(im, channels=3)\n",
    "#     large = tf.image.resize_images(img, size=(250, 250))\n",
    "#     loss = tf.cast(large, dtype=tf.uint8)\n",
    "\n",
    "    encoded_image_data = tf.image.encode_png(img)\n",
    "    \n",
    "    \n",
    "    height = im.shape[0]\n",
    "    width = im.shape[1]\n",
    "    image_format = b'png'\n",
    "\n",
    "    xmins = [x1]\n",
    "    xmaxs = [x2]\n",
    "    ymins = [y1]\n",
    "    ymaxs = [y2]\n",
    "    classes_text = [class_map[lab]]\n",
    "    classes = [lab]\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "      'image/filename': bytes_feature(filename),\n",
    "      'image/source_id': bytes_feature(filename),\n",
    "      'image/encoded': bytes_feature(encoded_image_data),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "      'image/object/class/text': bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': int64_list_feature(classes)}))\n",
    "\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000' [Op:DecodePng]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-07f997fcf740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bound_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcreate_cat_tf_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-109-9d99179f1f98>\u001b[0m in \u001b[0;36mcreate_cat_tf_example\u001b[0;34m(img_data)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#     large = tf.image.resize_images(img, size=(250, 250))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     loss = tf.cast(large, dtype=tf.uint8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mdecode_png\u001b[0;34m(contents, channels, dtype, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DecodePng\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         tld.op_callbacks, contents, \"channels\", channels, \"dtype\", dtype)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexport_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexport_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m       \u001b[0mexport_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000' [Op:DecodePng]"
     ]
    }
   ],
   "source": [
    "for img_data in zip(train_files, train_images, train_bound_boxes, train_labels):\n",
    "    create_cat_tf_example(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
