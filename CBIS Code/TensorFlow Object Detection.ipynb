{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.models as models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.estimator as estimator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet, inception_v3\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "np.random.seed(123)\n",
    "img_dim = (250, 250)\n",
    "# cv2 is height, width, color channels\n",
    "data_dir = '/Users/jacksimonson/data/'\n",
    "# model_zoo = '/Users/jacksimonson/models/research/object_detection/g3doc/tf2_detection_zoo.md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write label-map pbtxt file\n",
    "label_map = {1: 'benign', 2: 'malignant'}\n",
    "\n",
    "def write_label_map(data_dir, mapping):\n",
    "    with open(\"{}label_map.pbtxt\".format(data_dir), 'a') as the_file:\n",
    "        for i, lab in mapping.items():\n",
    "            the_file.write('item\\n')\n",
    "            the_file.write('{\\n')\n",
    "            the_file.write('name: \"{}\"'.format(lab))\n",
    "            the_file.write('\\n')\n",
    "            the_file.write(\"id: {}\".format(i))\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('display_name: \"{}\"'.format(lab))\n",
    "            the_file.write('\\n')\n",
    "            the_file.write('}\\n')\n",
    "    print('Saved to {}label_map.pbtxt'.format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_label_map(data_dir, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bboxes(mask_path, img_dim):\n",
    "\n",
    "    \"\"\"Compute bounding boxes from masks.\n",
    "\n",
    "    mask: [height, width, num_instances]. Mask pixels are either 1 or 0.\n",
    "\n",
    " \n",
    "\n",
    "    Returns: bbox array [num_instances, (y1, x1, y2, x2)].\n",
    "\n",
    "    \"\"\"\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.resize(mask, img_dim)\n",
    "    mask[mask != 0] = 1\n",
    "\n",
    "    m = mask[:, :, 0]\n",
    "\n",
    "    # Bounding box.\n",
    "\n",
    "    horizontal_indicies = np.where(np.any(m, axis=0))[0]\n",
    "\n",
    "    vertical_indicies = np.where(np.any(m, axis=1))[0]\n",
    "\n",
    "    if horizontal_indicies.shape[0]:\n",
    "\n",
    "        x1, x2 = horizontal_indicies[[0, -1]]\n",
    "\n",
    "        y1, y2 = vertical_indicies[[0, -1]]\n",
    "\n",
    "        # x2 and y2 should not be part of the box. Increment by 1.\n",
    "\n",
    "        x2 += 1\n",
    "\n",
    "        y2 += 1\n",
    "\n",
    "    else:\n",
    "\n",
    "        # No mask for this instance. Might happen due to\n",
    "\n",
    "        # resizing or cropping. Set bbox to zeros\n",
    "\n",
    "        x1, x2, y1, y2 = 0, 0, 0, 0\n",
    "\n",
    "    return [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in mask_train:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, train_mask_path), img)\n",
    "#     print(img_path)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     print(im.shape)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, train_mask_jpg), file), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in mask_test:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, test_mask_path), img)\n",
    "#     print(img_path)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     print(im.shape)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, test_mask_jpg), file), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = 'training-image'\n",
    "train_jpg = 'training-image-jpg'\n",
    "test_image_path = 'test-image'\n",
    "test_jpg = 'test-image-jpg'\n",
    "train_mask_path = 'training-mask'\n",
    "train_mask_jpg = 'training-mask-jpg'\n",
    "test_mask_path = 'test-mask'\n",
    "test_mask_jpg = 'test-mask-jpg'\n",
    "\n",
    "train_images = [x for x in os.listdir(os.path.join(data_dir,train_jpg)) if x.endswith('.jpg')]\n",
    "test_images = [x for x in os.listdir(os.path.join(data_dir,test_jpg)) if x.endswith('.jpg')]\n",
    "mask_train = [x for x in os.listdir(os.path.join(data_dir,train_mask_jpg)) if x.endswith('.jpg')]\n",
    "mask_test = [x for x in os.listdir(os.path.join(data_dir,test_mask_jpg)) if x.endswith('.jpg')]\n",
    "\n",
    "# files = train_images, train_image_path, train_jpg\n",
    "# for img in train_images:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, train_image_path), img)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, train_jpg), file), im)\n",
    "\n",
    "# for img in test_images:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, test_image_path), img)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, test_jpg), file), im)\n",
    "    \n",
    "# for img in mask_train:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, train_mask_path), img)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, train_mask_jpg), file), im)\n",
    "    \n",
    "# for img in mask_test:\n",
    "#     file = img.split('/')[-1].replace('.png', '.jpg')\n",
    "#     img_path = os.path.join(os.path.join(data_dir, test_mask_path), img)\n",
    "#     im = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "#     cv2.imwrite(os.path.join(os.path.join(data_dir, test_mask_jpg), file), im)\n",
    "\n",
    "\n",
    "# find intersection of mammograms and masks\n",
    "train_files = sorted(list(set(train_images).intersection(set(mask_train))))\n",
    "test_files = sorted(list(set(test_images).intersection(set(mask_test))))\n",
    "\n",
    "train_file_names = [x for x in train_files if x.endswith('.jpg')]\n",
    "test_file_names = [x for x in test_files if x.endswith('.jpg')]\n",
    "\n",
    "train_files = [os.path.join(os.path.join(data_dir, train_jpg), img) for img in train_file_names]\n",
    "# train_images = []\n",
    "# for img in train_files:\n",
    "#     if not img.endswith('.jpg'):\n",
    "#         continue\n",
    "#     im = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "#     x = cv2.resize(im, img_dim)\n",
    "#     train_images += [x]\n",
    "# train_images = np.array(train_images)\n",
    "\n",
    "    \n",
    "test_files = [os.path.join(os.path.join(data_dir, test_jpg), img) for img in test_file_names]\n",
    "# test_images = []\n",
    "# for img in test_files:\n",
    "#     if not img.endswith('.jpg'):\n",
    "#         continue\n",
    "#     im = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "#     x = cv2.resize(im, img_dim)\n",
    "#     test_images += [x]\n",
    "# test_images = np.array(test_images)\n",
    "\n",
    "# encode labels\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# train_labels = [fn.split('/')[-1].split('_')[-1].replace('.jpg','').lower().strip() for fn in train_files]\n",
    "# le.fit(train_labels)\n",
    "# train_labels = le.transform(train_labels)\n",
    "\n",
    "# test_labels = [fn.split('/')[-1].split('_')[-1].replace('.jpg','').lower().strip() for fn in test_files]\n",
    "# test_labels = le.transform(test_labels)\n",
    "\n",
    "# # get bounding boxes\n",
    "mask_train_images = [os.path.join(os.path.join(data_dir, train_mask_jpg), img_name) for img_name in train_file_names]\n",
    "mask_test_images = [os.path.join(os.path.join(data_dir, test_mask_jpg), img_name) for img_name in test_file_names]\n",
    "\n",
    "# # get bounding boxes\n",
    "train_bound_boxes = np.array([extract_bboxes(img, img_dim) for img in mask_train_images if not img.endswith('.DS_Store')])\n",
    "test_bound_boxes = np.array([extract_bboxes(img, img_dim) for img in mask_train_images if not img.endswith('.DS_Store')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jacksimonson/data/test-image-jpg/Calc-Test_P_00038_LEFT_CC_BENIGN.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([143, 132, 201, 159])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bound_boxes = np.load('/Users/jacksimonson/data/training_bound_boxes.npy')\n",
    "test_bound_boxes = np.load('/Users/jacksimonson/data/test_bound_boxes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/jacksimonson/data/training-labels.npy', train_labels)\n",
    "np.save('/Users/jacksimonson/data/test-labels.npy', test_labels)\n",
    "np.save('/Users/jacksimonson/data/test-images-array.npy', test_images)\n",
    "np.save('/Users/jacksimonson/data/training-images-array.npy', train_images)\n",
    "np.save('/Users/jacksimonson/data/training_bound_boxes.npy', train_bound_boxes)\n",
    "np.save('/Users/jacksimonson/data/test_bound_boxes.npy', test_bound_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('/Users/jacksimonson/data/training-labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = np.load('/Users/jacksimonson/data/training-images-array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/jacksimonson/data/single_imgs_malignant.npy', imgs[0])\n",
    "np.save('/Users/jacksimonson/data/single_imgs_benign.npy', imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = np.load('/Users/jacksimonson/data/training-labels.npy')\n",
    "# test_labels = np.load('/Users/jacksimonson/data/test-labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {'benign':1, 'malignant':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = np.load('/Users/jacksimonson/data/training-images-array.npy')\n",
    "# test_images = np.load('/Users/jacksimonson/data/test-images-array.npy')\n",
    "# train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def read_examples_list(path):\n",
    "    \"\"\"Read list of training or validation examples.\n",
    "\n",
    "    The file is assumed to contain a single example per line where the first\n",
    "    token in the line is an identifier that allows us to find the image and\n",
    "    annotation xml for that example.\n",
    "\n",
    "    For example, the line:\n",
    "    xyz 3\n",
    "    would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n",
    "\n",
    "    Args:\n",
    "    path: absolute path to examples list file.\n",
    "\n",
    "    Returns:\n",
    "    list of example identifiers (strings).\n",
    "    \"\"\"\n",
    "    with tf.gfile.GFile(path) as fid:\n",
    "        lines = fid.readlines()\n",
    "    return [line.strip().split(' ')[0] for line in lines]\n",
    "\n",
    "\n",
    "def recursive_parse_xml_to_dict(xml):\n",
    "    \"\"\"Recursively parses XML contents to python dict.\n",
    "\n",
    "    We assume that `object` tags are the only ones that can appear\n",
    "    multiple times at the same level of a tree.\n",
    "\n",
    "    Args:\n",
    "    xml: xml tree obtained by parsing XML file contents using lxml.etree\n",
    "\n",
    "    Returns:\n",
    "    Python dictionary holding XML contents.\n",
    "    \"\"\"\n",
    "    if not xml:\n",
    "        return {xml.tag: xml.text}\n",
    "    result = {}\n",
    "    for child in xml:\n",
    "        child_result = recursive_parse_xml_to_dict(child)\n",
    "        if child.tag != 'object':\n",
    "            result[child.tag] = child_result[child.tag]\n",
    "        else:\n",
    "            if child.tag not in result:\n",
    "                result[child.tag] = []\n",
    "        result[child.tag].append(child_result[child.tag])\n",
    "    return {xml.tag: result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_tf_example(img_data):\n",
    "    img, box = img_data\n",
    "    im = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (250, 250))\n",
    "    cv2.imwrite(img, im)\n",
    "    fp = open(img, 'rb')\n",
    "    im_bytes = fp.read()\n",
    "    \n",
    "    x1,y1,x2,y2 = box\n",
    "\n",
    "    filename = tf.compat.as_bytes(img.split('/')[-1])\n",
    "    image_format = b'jpg'\n",
    "\n",
    "    encoded_image_data = im_bytes\n",
    "    \n",
    "    \n",
    "    height = 250\n",
    "    width = 250\n",
    "\n",
    "    xmins = [x1/width]\n",
    "    xmaxs = [x2/width]\n",
    "    ymins = [y1/height]\n",
    "    ymaxs = [y2/height]\n",
    "    classes_text = [tf.compat.as_bytes('benign')] if 'benign' in img.lower() else [tf.compat.as_bytes('malignant')]\n",
    "    classes = [1] if 'benign' in img.lower() else [2]\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': int64_feature(height),\n",
    "      'image/width': int64_feature(width),\n",
    "      'image/filename': bytes_feature(filename),\n",
    "      'image/source_id': bytes_feature(filename),\n",
    "      'image/encoded': bytes_feature(encoded_image_data),\n",
    "      'image/format': bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "      'image/object/class/text': bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': int64_list_feature(classes)}))\n",
    "\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.io.TFRecordWriter(os.path.join(data_dir, 'train.tfrecord'))\n",
    "for img_data in zip(train_files, train_bound_boxes):\n",
    "    tf_example = create_cat_tf_example(img_data)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.io.TFRecordWriter(os.path.join(data_dir, 'test.tfrecord'))\n",
    "for img_data in zip(test_files, test_bound_boxes):\n",
    "    tf_example = create_cat_tf_example(img_data)\n",
    "    writer.write(tf_example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# raw_dataset = tf.data.TFRecordDataset(os.path.join(data_dir, 'train.tfrecord'))\n",
    "\n",
    "# shards = 50\n",
    "\n",
    "# for i in range(shards):\n",
    "#     writer = tf.data.experimental.TFRecordWriter(f\"{os.path.join(data_dir, 'train')}-{i}.tfrecord\")\n",
    "#     writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dataset = tf.data.TFRecordDataset(os.path.join(data_dir, 'test.tfrecord'))\n",
    "\n",
    "# shards = 12\n",
    "\n",
    "# for i in range(shards):\n",
    "#     writer = tf.data.experimental.TFRecordWriter(f\"{os.path.join(data_dir, 'test')}-{i}.tfrecord\")\n",
    "#     writer.write(raw_dataset.shard(shards, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push individual shards instead of one big one\n",
    "# Update config file, push to repo\n",
    "# Set up Paperspace project using this structure instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
