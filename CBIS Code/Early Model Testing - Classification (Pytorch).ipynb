{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from ignite.metrics import EpochMetric\n",
    "from torchvision import datasets, transforms\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.metrics import roc_auc, ROC_AUC, RocCurve\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer, Events\n",
    "from ignite.metrics import Accuracy, Precision, Recall, ConfusionMatrix, Fbeta, Loss, MetricsLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to help set the final classifier layer and other basic model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-process the data to make sure it is properly formatted for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process the image data for training and validation sets\n",
    "\n",
    "def preprocess_data(train_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Train',\n",
    "                    test_data_dir = '/Users/jacksimonson/Documents/CBIS-DDSM Val'):\n",
    "\n",
    "    # transform the train and validation data\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # standard pytorch normalization values\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "    # collect in a dictionary\n",
    "    image_datasets = {}\n",
    "    image_datasets['train'] = datasets.ImageFolder(train_data_dir, data_transforms['train'])\n",
    "    image_datasets['val'] = datasets.ImageFolder(test_data_dir, data_transforms['val'])\n",
    "\n",
    "\n",
    "    # create data loaders\n",
    "    dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    class_names = image_datasets['val'].classes\n",
    "\n",
    "    return class_names, dataset_sizes, dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This function is the global one. It initializes the model, the parameters that need to be trained/tuned, processes the data, and runs the trainier and executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(model_name = 'alexnet', use_pretrained = True, num_classes = 2, num_epochs = 25, device = torch.device(\"cpu\"),\n",
    "                    feature_extract = True, criterion = nn.CrossEntropyLoss()):\n",
    "    # Initialize the model for this run\n",
    "    model = models.resnet18(pretrained=use_pretrained) if model_name == 'resnet' else models.resnet18(pretrained=use_pretrained)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    input_size = 224\n",
    "    model, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "    # Print the model we just instantiated\n",
    "    print(model)\n",
    "\n",
    "    # get data downloaders\n",
    "    class_names, dataset_sizes, dataloaders_dict = preprocess_data()\n",
    "    \n",
    "    # Send the model to GPU/CPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Gather the parameters to be optimized/updated in this run\n",
    "    params_to_update = model.parameters()\n",
    "    print(\"Params to learn:\")\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                print(\"\\t\",name)\n",
    "\n",
    "    # Observe that all parameters are being optimized\n",
    "    optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
    "    \n",
    "    train_dl = dataloaders_dict['train']\n",
    "    val_dl = dataloaders_dict['val']\n",
    "    \n",
    "    \n",
    "    # create a trainer and evaluator using the ignite package to train and evaluate the models\n",
    "    trainer = create_supervised_trainer(model, optimizer_ft, criterion, device)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics={'accuracy': Accuracy(),\n",
    "                                                     'confusion': ConfusionMatrix(num_classes = 2),\n",
    "                                                     'loss': Loss(criterion)},\n",
    "                                            device=device)\n",
    "    \n",
    "    def thresholded_output_transform(output):\n",
    "        y_pred, y = output\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        return y_pred, y\n",
    "             \n",
    "     # attach additional metrics\n",
    "    precision = Precision(average=False)\n",
    "    recall = Recall(average=False)\n",
    "    F1 = (precision * recall * 2 / (precision + recall)).mean()\n",
    "\n",
    "    precision.attach(evaluator, 'precision')\n",
    "    recall.attach(evaluator, 'recall')\n",
    "    F1.attach(evaluator, 'F1')\n",
    "    \n",
    "    # why won't this work??? bad input shape\n",
    "#     ROC_AUC(output_transform=thresholded_output_transform).attach(evaluator, 'ROC')\n",
    "\n",
    "    \n",
    "    \n",
    "    val_accuracy = []\n",
    "    train_accuracy = []\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(trainer):\n",
    "        evaluator.run(train_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "        train_accuracy.append(metrics['accuracy'])\n",
    "#         print(\n",
    "#             f\"Training Results   - Epoch: {trainer.state.epoch}  \"\n",
    "#             f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "#             f\"loss: {metrics['loss']:.2f} \"\n",
    "#             f\"prec: {metrics['precision'].cpu()} \"\n",
    "#             f\"recall: {metrics['recall'].cpu()} \"\n",
    "#             f\"F1: {metrics['F1']}\")\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_dl)\n",
    "        metrics = evaluator.state.metrics\n",
    "        val_accuracy.append(metrics['accuracy'])\n",
    "#         print(\n",
    "#             f\"Validation Results - Epoch: {trainer.state.epoch}  \"\n",
    "#             f\"accuracy: {metrics['accuracy']:.2f} \"\n",
    "#             f\"loss: {metrics['loss']:.2f} \"\n",
    "#             f\"prec: {metrics['precision'].cpu()} \"\n",
    "#             f\"recall: {metrics['recall'].cpu()} \"\n",
    "#             f\"F1: {metrics['F1']}\")\n",
    "\n",
    "    trainer.run(train_dl, max_epochs=50)\n",
    "    return trainer, evaluator, train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# run the analysis on alexnet and resnet\n",
    "models_final = {}\n",
    "for model in ['resnet']:\n",
    "    trainer, evaluator, train_accuracy, val_accuracy = build_and_train(model)\n",
    "    models_final[model] = (trainer, evaluator, train_accuracy, val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5761458846722524,\n",
       " 0.6816165598817151,\n",
       " 0.6037456875308034,\n",
       " 0.6155741744701824,\n",
       " 0.6954164613109907,\n",
       " 0.7097092163627403,\n",
       " 0.6515524889107935,\n",
       " 0.6407097092163627,\n",
       " 0.7195662888122227,\n",
       " 0.7304090685066535,\n",
       " 0.7121734844751109,\n",
       " 0.6663380975850173,\n",
       " 0.7102020699852144,\n",
       " 0.6323311976343026,\n",
       " 0.6752094627895515,\n",
       " 0.7225234105470675,\n",
       " 0.7259733859043864,\n",
       " 0.6919664859536717,\n",
       " 0.7299162148841793,\n",
       " 0.7220305569245934,\n",
       " 0.6407097092163627,\n",
       " 0.6461310990635781,\n",
       " 0.7249876786594381,\n",
       " 0.7146377525874815,\n",
       " 0.6791522917693446,\n",
       " 0.7220305569245934,\n",
       " 0.7387875800887137,\n",
       " 0.6274026614095614,\n",
       " 0.6939379004435683,\n",
       " 0.720551996057171,\n",
       " 0.7387875800887137,\n",
       " 0.681123706259241,\n",
       " 0.7161163134549039,\n",
       " 0.7171020206998522,\n",
       " 0.6136027599802859,\n",
       " 0.7392804337111878,\n",
       " 0.7353376047313948,\n",
       " 0.6885165105963529,\n",
       " 0.7028092656481025,\n",
       " 0.7294233612617053,\n",
       " 0.7230162641695417,\n",
       " 0.7111877772301627,\n",
       " 0.6382454411039921,\n",
       " 0.7348447511089207,\n",
       " 0.7136520453425332,\n",
       " 0.700837851158206,\n",
       " 0.7037949728930508,\n",
       " 0.6239526860522425,\n",
       " 0.7013307047806802,\n",
       " 0.7259733859043864]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_final['resnet'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6833333333333333,\n",
       " 0.5833333333333334,\n",
       " 0.7083333333333334,\n",
       " 0.65,\n",
       " 0.6083333333333333,\n",
       " 0.6,\n",
       " 0.6583333333333333,\n",
       " 0.675,\n",
       " 0.6333333333333333,\n",
       " 0.625,\n",
       " 0.6416666666666667,\n",
       " 0.5,\n",
       " 0.6166666666666667,\n",
       " 0.675,\n",
       " 0.5166666666666667,\n",
       " 0.6166666666666667,\n",
       " 0.625,\n",
       " 0.6583333333333333,\n",
       " 0.625,\n",
       " 0.5833333333333334,\n",
       " 0.6583333333333333,\n",
       " 0.49166666666666664,\n",
       " 0.6166666666666667,\n",
       " 0.65,\n",
       " 0.6833333333333333,\n",
       " 0.5666666666666667,\n",
       " 0.6333333333333333,\n",
       " 0.65,\n",
       " 0.55,\n",
       " 0.5833333333333334,\n",
       " 0.6166666666666667,\n",
       " 0.7083333333333334,\n",
       " 0.6333333333333333,\n",
       " 0.5416666666666666,\n",
       " 0.6916666666666667,\n",
       " 0.5666666666666667,\n",
       " 0.6333333333333333,\n",
       " 0.6833333333333333,\n",
       " 0.7,\n",
       " 0.6333333333333333,\n",
       " 0.6083333333333333,\n",
       " 0.65,\n",
       " 0.6916666666666667,\n",
       " 0.65,\n",
       " 0.5583333333333333,\n",
       " 0.65,\n",
       " 0.6833333333333333,\n",
       " 0.6666666666666666,\n",
       " 0.6916666666666667,\n",
       " 0.55]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_final['resnet'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(train_acc)-1), train_acc)\n",
    "# plt.plot(range(len(val_acc)-1), val_acc)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
